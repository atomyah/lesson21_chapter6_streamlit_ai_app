import os
from dotenv import load_dotenv
import streamlit as st
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory


load_dotenv() 

### StreamlitCallbackHandlerã‚¯ãƒ©ã‚¹ï¼ˆã‚«ã‚¹ã‚¿ãƒ ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼‰ã®å®šç¾©(StreamingStdOutCallbackHandlerã‚’ç¶™æ‰¿)
class StreamlitCallbackHandler(StreamingStdOutCallbackHandler):
    def __init__(self, container: st.delta_generator.DeltaGenerator, initial_text: str = ""):
        self.container = container  ## Streamlitã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼ˆst.empty()ã§ä½œæˆã—ãŸè¡¨ç¤ºé ˜åŸŸï¼‰ã€‚st.delta_generator.DeltaGeneratorã¯Streamlitã®è¡¨ç¤ºè¦ç´ ã‚’æ‰±ã†ã‚¯ãƒ©ã‚¹ã®å‹
        self.text = initial_text    ## self.textã¯ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚’è“„ç©ã™ã‚‹ãŸã‚ã®å¤‰æ•°ï¼ˆåˆæœŸå€¤ã¯ç©ºæ–‡å­—åˆ—ï¼‰
        # self.new_line = True    
        
    def on_llm_new_token(self, token: str, **kwargs) -> None:   #### LLMãŒæ–°ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ãŸã³ã«å‘¼ã³å‡ºã•ã‚Œã‚‹é–¢æ•°ã€‚
                                                                #### StreamingStdOutCallbackHandlerï¼‰ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã—ã¦ã„ã‚‹
                                                                #### token: LLMã‹ã‚‰æ–°ã—ãç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®æ–­ç‰‡. **kwargs: ãã®ä»–ã®å¼•æ•°(ä½¿ç”¨ã—ã¦ã„ãªã„)
        self.text += token
        self.container.markdown(f"ğŸ¤– **å°‚é–€å®¶**: {self.text}â–Œ") #### Streamlitã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’æ›´æ–°ã€‚ğŸ¤– çµµæ–‡å­—ã‚’è¿½åŠ ã€‚â–Œã¯ã‚«ãƒ¼ã‚½ãƒ«

#######################################################################################################################################################
# ã€StreamingStdOutCallbackHandlerã‚’ç¶™æ‰¿ã—ãŸStreamlitCallbackHandlerã‚’ä½œæˆã™ã‚‹ãƒ¯ã‚±ã€‘
# llm = ChatOpenAI(
#     model_name="gpt-4o-mini",temperature=0.5,streaming=True,callbacks=[StreamingStdOutCallbackHandler()]
# )
# ã“ã®æ¨™æº–çš„ãªæ›¸ãæ–¹ã ã¨å‡ºåŠ›ã¯æ¨™æº–å‡ºåŠ›ï¼ˆstdoutï¼‰ã«ã®ã¿ã§Streamlitã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«ã¯è¡¨ç¤ºã•ã‚Œãªã„ï¼ãƒˆãƒ¼ã‚¯ãƒ³ã®åˆ¶å¾¡ã‚„ä¿å­˜ã‚‚ã§ããªã„ï¼

# ã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ã¦Streamlitã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«è¡¨ç¤ºã™ã‚‹ã‚ˆã†ã«ã—ãŸçµæœã€ã“ã®ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã«ã‚ˆã‚Šã€ä»¥ä¸‹ã®UIè¡¨ç¤ºã‚’å®Ÿç¾ã€‚
# "ã“" â†’ ğŸ¤– **å°‚é–€å®¶**: ã“â–Œ
# "ã‚“" â†’ ğŸ¤– **å°‚é–€å®¶**: ã“ã‚“â–Œ
# "ã«" â†’ ğŸ¤– **å°‚é–€å®¶**: ã“ã‚“ã«â–Œ
# "ã¡" â†’ ğŸ¤– **å°‚é–€å®¶**: ã“ã‚“ã«ã¡â–Œ
# "ã¯" â†’ ğŸ¤– **å°‚é–€å®¶**: ã“ã‚“ã«ã¡ã¯â–Œ
#######################################################################################################################################################




############################### process_questioné–¢æ•°ã€€#####################################
def process_question(genre: str, question: str) -> None:
    # ãƒ¡ãƒ¢ãƒªã‹ã‚‰å±¥æ­´ã‚’å–å¾—
    chat_history = st.session_state.memory.load_memory_variables({})["chat_history"]
    
    # ä¼šè©±å±¥æ­´ã®è¡¨ç¤º
    for i, message in enumerate(st.session_state["talks"]):
        if i % 2 == 0:
            st.markdown(f"ğŸ™‚ **ã‚ãªãŸ**: {message}")
        else:
            st.markdown(f"ğŸ¤– **{genre}å°‚é–€å®¶**: {message}")
    
    # æœ€æ–°ã®è³ªå•ã‚’è¡¨ç¤º
    st.markdown(f"ğŸ™‚ **ã‚ãªãŸ**: {question}")
    
    # Streamlitã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼ˆè¡¨ç¤ºé ˜åŸŸï¼‰ã‚’ä½œæˆ
    answer_placeholder = st.empty() #### UIã«ç©ºã®è¡¨ç¤ºé ˜åŸŸã‚’ä½œæˆ(MessagesPlaceholderã¨ã¯é–¢ä¿‚ãªã„).
    
    # ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®ä½œæˆ
    callback = StreamlitCallbackHandler(answer_placeholder)     #### answer_placeholderå¼•æ•°ã¯ã€def __init__()ã®å¼•æ•°container: st.delta_generator.DeltaGeneratorã®ã“ã¨
    
    # ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
    llm = ChatOpenAI(
        model_name="gpt-4o-mini",
        temperature=0.5,
        streaming=True,
        callbacks=[callback]
    )
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(
            "ã‚ãªãŸã¯{genre}ã®å°‚é–€å®¶ã§ã™ã€‚è³ªå•ã«å¯¾ã—ã¦åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ãç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
        ),
        MessagesPlaceholder(variable_name="chat_history"),
        HumanMessagePromptTemplate.from_template("{question}")
    ])
    
    # å¿œç­”ã®ç”Ÿæˆ
    result = llm(
        prompt.format_messages(
            genre=genre,
            question=question,
            chat_history=chat_history
        )
    )

    # å±¥æ­´ã®æ›´æ–°
    st.session_state["talks"].append(question)
    st.session_state["talks"].append(callback.text)
    
    # ãƒ¡ãƒ¢ãƒªã®æ›´æ–°
    st.session_state.memory.save_context(
        {"input": question},
        {"output": callback.text}
    )
############################### process_questioné–¢æ•°~ã“ã“ã¾ã§ã€€#####################################



# ãƒ¡ã‚¤ãƒ³ã®UIéƒ¨åˆ†
st.title("ã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ—ãƒª: äºŒäººã®å°‚é–€å®¶ã«ç›¸è«‡ã—ã‚ˆã†ï¼")
st.write("##### å°‚é–€å®¶1: åŒ»ç™‚ã¨å…ˆç«¯æ²»ç™‚ã®å°‚é–€å®¶")
st.write("åŒ»ç™‚ç•Œã®å…ˆç«¯æŠ€è¡“ã¨æœ€æ–°æƒ…å ±ã‚’èãã“ã¨ãŒã§ãã¾ã™ã€‚")
st.write("##### å°‚é–€å®¶2: ã‚¹ãƒ”ãƒªãƒãƒ¥ã‚¢ãƒ«ã®å°‚é–€å®¶")
st.write("ã‚¹ãƒ”ãƒªãƒãƒ¥ã‚¢ãƒ«ã¨å®‡å®™ã®ä»•çµ„ã¿ã‚’èãã“ã¨ãŒã§ãã¾ã™ã€‚")

st.divider()    ## åŒºåˆ‡ã‚Šç·š

# åˆæœŸåŒ–ã‚³ãƒ¼ãƒ‰
if "talks" not in st.session_state:
    st.session_state["talks"] = []

if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(
        return_messages=True,
        memory_key="chat_history",
        max_token_limit=1000
    )

# å°‚é–€å®¶ã®é¸æŠ
selected_item = st.radio(
    "å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
    ["åŒ»ç™‚å°‚é–€å®¶", "ã‚¹ãƒ”ãƒªãƒãƒ¥ã‚¢ãƒ«å°‚é–€å®¶"]
)

# è³ªå•å…¥åŠ›ã¨å‡¦ç†
if selected_item == "åŒ»ç™‚å°‚é–€å®¶":
    question = st.chat_input("åŒ»ç™‚å°‚é–€å®¶ã«è³ªå•ã—ã¦ãã ã•ã„ã€‚")
    if question:
        process_question("åŒ»ç™‚", question)
elif selected_item == "ã‚¹ãƒ”ãƒªãƒãƒ¥ã‚¢ãƒ«å°‚é–€å®¶":
    question = st.chat_input("ã‚¹ãƒ”ãƒªãƒãƒ¥ã‚¢ãƒ«ã®å°‚é–€å®¶ã«è³ªå•ã—ã¦ãã ã•ã„ã€‚")
    if question:
        process_question("ã‚¹ãƒ”ãƒªãƒãƒ¥ã‚¢ãƒ«", question)
## ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: pip install langchain==0.3.0 openai==1.47.0 langchain-community==0.3.0 langchain-openai==0.2.2 httpx==0.27.2
import os
from dotenv import load_dotenv  ## pip install python-dotenvã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¿…è¦
import streamlit as st
from langchain.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory

from langchain.schema.output_parser import StrOutputParser ## StrOutputParserãƒã‚§ã‚¤ãƒ³ã‚’ä½¿ã£ã¦å›ç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º

# from langchain.chains import ConversationChain

load_dotenv()   ## .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆã“ã“ã§OPEN_API_KEYã‚’èª­ã¿è¾¼ã‚“ã§ã„ã‚‹ï¼ã—ãŸãŒã£ã¦ãƒ»ãƒ»ãƒ»ğŸ‘‡ï¼‰
# openai_api_key = os.getenv("OPENAI_API_KEY")  ## ğŸ‘‰ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¦ã„ã‚‹ã“ã®ï¼‘æ–‡ã¯ä¸è¦


st.title("ã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ—ãƒª: äºŒäººã®å°‚é–€å®¶ã«ç›¸è«‡ã—ã‚ˆã†ï¼")
st.write("##### å°‚é–€å®¶1: åŒ»ç™‚ã¨å…ˆç«¯æ²»ç™‚ã®å°‚é–€å®¶")
st.write("åŒ»ç™‚ç•Œã®å…ˆç«¯æŠ€è¡“ã¨æœ€æ–°æƒ…å ±ã‚’èãã“ã¨ãŒã§ãã¾ã™ã€‚")
st.write("##### å°‚é–€å®¶2: ã‚¹ãƒ”ãƒªãƒãƒ¥ã‚¢ãƒ«ã®å°‚é–€å®¶")
st.write("ã‚¹ãƒ”ãƒªãƒãƒ¥ã‚¢ãƒ«ã¨å®‡å®™ã®ä»•çµ„ã¿ã‚’èãã“ã¨ãŒã§ãã¾ã™ã€‚")


selected_item = st.radio(
    "å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
    ["åŒ»ç™‚å°‚é–€å®¶", "ã‚¹ãƒ”ãƒªãƒãƒ¥ã‚¢ãƒ«å°‚é–€å®¶"]
)

st.divider()    ## åŒºåˆ‡ã‚Šç·š

## ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5, streaming=True)

# StrOutputParserã®åˆæœŸåŒ–
output_parser = StrOutputParser()

## ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
system_template = "ã‚ãªãŸã¯{genre}ã®å°‚é–€å®¶ã§ã™ã€‚è³ªå•ã«å¯¾ã—ã¦åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ãç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚{genre}ä»¥å¤–ã®è³ªå•ã«ã¯ç­”ãˆãªã„ã§ãã ã•ã„ã€‚"
human_template = "ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼š{question}"

## ChatPromptTemplateã‚’ç”Ÿæˆ
prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(system_template),
    MessagesPlaceholder(  # å±¥æ­´ç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’è¿½åŠ . Placeholderï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼‰ã¨ã¯ã€Œä½•ã‚‰ã‹ã®å€¤ãŒå…¥ã£ã¦ãã‚‹ã¾ã§ä¸€æ™‚çš„ã«ç¢ºä¿ã•ã‚Œã‚‹å ´æ‰€ã€
        variable_name="chat_history"    ## variable_name="history" ã‚’æŒ‡å®šã—ã¦ã‚‹ãŒã“ã‚Œã«ã‚ˆã‚Šä¼šè©±å±¥æ­´ãŒå­˜åœ¨ã™ã‚‹å ´åˆãã®å†…å®¹ãŒã“ã“ã«æŒ¿å…¥ã•ã‚Œã‚‹
    ),
    HumanMessagePromptTemplate.from_template(human_template),
])

# ãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆï¼ˆoutput_parserã¯StrOutputParserã€æ–‡å­—åˆ—è¡¨ç¤ºï¼‰
chain = prompt | llm | output_parser



# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ï¼ˆConversationBufferMemoryã§ä¿æŒã™ã‚‹å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã¨ã¯åˆ¥ç‰©ï¼UIã«ä¼šè©±è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ã‚¹ãƒ†ãƒ¼ãƒˆï¼‰
if "talks" not in st.session_state:
    st.session_state["talks"] = []


# ãƒ¡ãƒ¢ãƒªã®åˆæœŸåŒ–ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ç®¡ç†
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(
        return_messages=True,   ## # ãƒ¡ãƒ¢ãƒªã®åˆæœŸåŒ–æ™‚ã«è¿”ä¿¡ã®å½¢å¼ã‚’æŒ‡å®š
        memory_key="chat_history",
        max_token_limit=1000
    )


################################################################################
################ è³ªå•ã‚’å‡¦ç†ã™ã‚‹é–¢æ•°ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å½¢å¼ã§å›ç­”ã‚’è¡¨ç¤ºï¼‰################
################################################################################
def process_question(genre: str, question: str) -> None:
    """è³ªå•ã‚’å‡¦ç†ã—ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å½¢å¼ã§å›ç­”ã‚’è¡¨ç¤ºã™ã‚‹"""
    # ãƒ¡ãƒ¢ãƒªã‹ã‚‰å±¥æ­´ã‚’å–å¾—
    chat_history = st.session_state.memory.load_memory_variables({})["chat_history"]

    # ã¾ãšã€å‰å›ã¾ã§ã®ä¼šè©±å±¥æ­´ã‚’è¡¨ç¤ºï¼ˆst.session_state["talks"]ã®å†…å®¹ã‚’é †ç•ªã«è¡¨ç¤ºï¼‰
    for i, message in enumerate(st.session_state["talks"]):
        if i % 2 == 0:
            st.markdown(f"ğŸ™‚ **ã‚ãªãŸ**: {message}")
        else:
            st.markdown(f"ğŸ¤– **{genre}å°‚é–€å®¶**: {message}")
    
    # æœ€æ–°ã®è³ªå•ã‚’è¡¨ç¤ºï¼ˆã¾ã st.session_state["talks"]ã«ã¯è¿½åŠ ã•ã‚Œã¦ã„ãªã„ï¼ãã®å¾ŒğŸ‘‡ï¼‰
    st.markdown(f"ğŸ™‚ **ã‚ãªãŸ**: {question}")

    # å›ç­”ç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ä½œæˆ
    answer_placeholder = st.empty() # UIã«ç©ºã®è¡¨ç¤ºé ˜åŸŸã‚’ä½œæˆ(MessagesPlaceholderã¨ã¯é–¢ä¿‚ãªã„).
    full_response = ""  # å›ç­”ã®é€”ä¸­çµŒéã‚’ä¿æŒã™ã‚‹å¤‰æ•°

    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å½¢å¼ã§å›ç­”ã‚’ç”Ÿæˆãƒ»è¡¨ç¤º
    for chunk in chain.stream({
        "genre": genre,
        "question": question,
        "chat_history": chat_history
    }):
        full_response += chunk
        answer_placeholder.markdown(f"ğŸ¤– **{genre}å°‚é–€å®¶**: {full_response}â–Œ")
        # ã“ã“ã§ã¯å›ç­”ãŒç”Ÿæˆã•ã‚Œã‚‹é€”ä¸­çµŒéã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™
        # â–Œè¨˜å·ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ¼ã‚½ãƒ«ã‚’æ¨¡æ“¬ã—ã¦ã‚‹ï¼ä¾‹ï¼šã€Œã“ã‚“ã«â–Œã€â†’ã€Œã“ã‚“ã«ã¡â–Œã€â†’ã€Œã“ã‚“ã«ã¡ã¯â–Œã€

    # æœ€çµ‚çš„ãªå›ç­”ã‚’è¡¨ç¤ºï¼ˆã‚«ãƒ¼ã‚½ãƒ«ã‚’æ¶ˆã™ï¼‰
    answer_placeholder.markdown(f"ğŸ¤– **{genre}å°‚é–€å®¶**: {full_response}")  # æœ€çµ‚çš„ãªå›ç­”ã‚’å¾—ã‚‹ï¼ˆã‚«ãƒ¼ã‚½ãƒ«ãªã—ï¼‰  

    # ğŸ‘‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Œäº†å¾Œã«è³ªå•ã¨å›ç­”ã‚’å±¥æ­´ã«è¿½åŠ ï¼ˆã“ã‚Œã‚‰ã¯æ¬¡å›ã®ä¼šè©±æ™‚ã«ã€Œéå»ã®ä¼šè©±å±¥æ­´ã€ã¨ã—ã¦è¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ã«ãªã‚‹ï¼‰
    st.session_state["talks"].append(question)
    st.session_state["talks"].append(full_response)

    # ä¼šè©±ã‚’ä¿å­˜ï¼ˆæ¬¡å›ã®MessagesPlaceholderã§ä½¿ç”¨ã™ã‚‹ãŸã‚LangChainã®ãƒ¡ãƒ¢ãƒªã«ä¿å­˜ï¼‰
    st.session_state.memory.save_context(
        {"input": question},
        {"output": full_response}
    )
################################################################################
############################ è³ªå•ã‚’å‡¦ç†ã™ã‚‹é–¢æ•°ã€ã“ã“ã¾ã§ #########################
################################################################################

    # è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ç”¨ã®JavaScript
    js = f"""
    <script>
        window.scrollTo(0, document.body.scrollHeight);
    </script>
    """
    st.components.v1.html(js, height=0)



# ãƒ¡ã‚¤ãƒ³ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å‡¦ç†
if selected_item == "åŒ»ç™‚å°‚é–€å®¶":
    question = st.chat_input("åŒ»ç™‚å°‚é–€å®¶ã«è³ªå•ã—ã¦ãã ã•ã„ã€‚")
    if question:
        process_question("åŒ»ç™‚", question)

elif selected_item == "ã‚¹ãƒ”ãƒªãƒãƒ¥ã‚¢ãƒ«å°‚é–€å®¶":
    question = st.chat_input("ã‚¹ãƒ”ãƒªãƒãƒ¥ã‚¢ã®å°‚é–€å®¶ã«è³ªå•ã—ã¦ãã ã•ã„ã€‚")
    if question:
        process_question("ã‚¹ãƒ”ãƒªãƒãƒ¥ã‚¢ãƒ«", question)






# ä¼šè©±å±¥æ­´ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
print("\n=== ä¼šè©±å±¥æ­´ ===")
conversation_history = st.session_state.memory.load_memory_variables({})["chat_history"]
print(conversation_history)